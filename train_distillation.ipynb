{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 20:30:27.036075: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-11 20:30:27.036221: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-11 20:30:27.048868: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-11 20:30:27.100189: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-11 20:30:28.278889: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from utils.models import Detector, EmbeddingModel\n",
    "from utils import common, tal, losses\n",
    "from utils.dataset import DecklistDataset\n",
    "from utils import db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"datasets/train.csv\")\n",
    "id_list = X_train[\"id\"].tolist()\n",
    "prefix = \"datasets/card_images_small/\"\n",
    "id_list = list(map(lambda x: prefix + str(x) + \".jpg\", id_list))\n",
    "card_type = list(map(lambda x: x.lower().startswith(\"pendulum\"), X_train[\"type\"].tolist()))\n",
    "train_dataset = DecklistDataset(id_list, card_type)\n",
    "del X_train, card_type, id_list\n",
    "\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=train_dataset.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = pd.read_csv(\"datasets/valid.csv\")\n",
    "id_list = X_valid[\"id\"].tolist()\n",
    "prefix = \"datasets/card_images_small/\"\n",
    "id_list = list(map(lambda x: prefix + str(x) + \".jpg\", id_list))\n",
    "card_type = list(map(lambda x: x.lower().startswith(\"pendulum\"), X_valid[\"type\"].tolist()))\n",
    "valid_dataset = DecklistDataset(id_list, card_type)\n",
    "del X_valid, card_type, id_list\n",
    "\n",
    "batch_size = 8\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, batch_size=batch_size, shuffle=True, collate_fn=valid_dataset.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model = YOLO(\"weights/yolov8n_detector.pt\")\n",
    "pre_model_dict = pre_model.model.model.state_dict()\n",
    "\n",
    "student_model = Detector(1000)\n",
    "model_dict = student_model.state_dict()\n",
    "\n",
    "for key in pre_model_dict.keys():\n",
    "    new_key = f\"layer{key}\"\n",
    "    model_dict[new_key] = pre_model_dict[key].clone().detach()\n",
    "\n",
    "student_model.load_state_dict(model_dict)\n",
    "student_model = student_model.cuda()\n",
    "\n",
    "for name, param in student_model.named_parameters():\n",
    "    param.requires_grad_(False if \"dfl\" in name else True)\n",
    "\n",
    "del pre_model, pre_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"best_134 copy.pt\")\n",
    "student_model.load_state_dict(state_dict)\n",
    "student_model = student_model.cuda()\n",
    "\n",
    "for name, param in student_model.named_parameters():\n",
    "    param.requires_grad_(False if \"dfl\" in name else True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 20:30:36.642812: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 20:30:36.647123: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 20:30:36.647252: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 20:30:36.669538: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 20:30:36.669831: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 20:30:36.669922: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 20:30:36.671269: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 20:30:36.671660: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 20:30:36.671696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-02-11 20:30:36.671861: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 20:30:36.671972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5991 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# prevent tenosrflow occupy all gpu memory\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "teach_preprocess = common.EmbeddingPreprocessor()\n",
    "teacher_model = EmbeddingModel()\n",
    "teacher_model.load(\"weights/embedding.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches = 400\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "task_aligned_assigner = tal.TaskAlignedAssigner(num_classes=1, alpha=0.5, beta=6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(model, lr=0.002, momentum=0.9, decay=1e-5):\n",
    "    g = [], [], []  # optimizer parameter groups\n",
    "    bn = tuple(v for k, v in nn.__dict__.items() if \"Norm\" in k)\n",
    "\n",
    "    for param_name, param in model.named_parameters():\n",
    "        if \"bias\" in param_name:  # bias (no decay)\n",
    "            g[2].append(param)\n",
    "        elif isinstance(param, bn):  # weight (no decay)\n",
    "            g[1].append(param)\n",
    "        else:  # weight (width decay)\n",
    "            g[0].append(param)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        g[2],\n",
    "        lr=lr,\n",
    "        betas=(momentum, 0.999),\n",
    "        weight_decay=0.0,\n",
    "    )\n",
    "    optimizer.add_param_group({\"params\": g[0], \"weight_decay\": decay})\n",
    "    optimizer.add_param_group({\"params\": g[1], \"weight_decay\": 0.0})\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def optimizer_step(model, optimizer, scaler):\n",
    "    scaler.unscale_(optimizer)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "optimizer = make_optimizer(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = next(student_model.parameters()).device\n",
    "detection_loss = losses.v8DetectionLoss(head=student_model.layer22, device=device, tal_topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_preprocessor = common.EmbeddingPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: cpus",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: cpus"
     ]
    }
   ],
   "source": [
    "torch.device(\"cpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_epoch(epoch, dataloader, student_model, teacher_model, is_train, optimizer=None, scaler=None):\n",
    "    device = next(student_model.parameters()).device\n",
    "    dtype = next(student_model.parameters()).dtype\n",
    "\n",
    "    total_loss = torch.zeros(4)\n",
    "    sample_count = 0\n",
    "    for batch in dataloader:\n",
    "        images = batch[\"image\"]\n",
    "\n",
    "        # preprocessing\n",
    "        student_inputs = common.detector_preprocessing(images).to(device=device)\n",
    "        batch[\"bboxes\"] = torch.from_numpy(batch[\"xywh\"])\n",
    "        batch[\"batch_idx\"] = torch.from_numpy(batch[\"batch_idx\"])\n",
    "        # groud-truth classes\n",
    "        batch[\"cls\"] = torch.zeros(\n",
    "            size=[batch[\"bboxes\"].shape[0], 1],\n",
    "            dtype=dtype\n",
    "        )\n",
    "\n",
    "        # make embeddings with teacher model\n",
    "        gt_embedding = []\n",
    "        for i, img in enumerate(images):\n",
    "            mask = batch[\"batch_idx\"] == i\n",
    "            teacher_inputs = []\n",
    "            img_width, img_height, _ = img.shape\n",
    "            xyxy_list = batch[\"xyxy\"][mask]\n",
    "            xyxy_list[:, [0, 2]] *= img_width\n",
    "            xyxy_list[:, [1, 3]] *= img_height\n",
    "            xyxy_list = np.round(xyxy_list).astype(np.int32)\n",
    "            for xyxy in xyxy_list:\n",
    "                x1, y1, x2, y2 = xyxy\n",
    "                crop = img[y1:y2, x1:x2, :]\n",
    "                crop = teacher_preprocessor(crop)\n",
    "                teacher_inputs.append(crop)\n",
    "            teacher_inputs = tf.stack(teacher_inputs)\n",
    "            teacher_embedding = teacher_model.pred(teacher_inputs, 8)\n",
    "            teacher_embedding = torch.from_numpy(teacher_embedding)\n",
    "            gt_embedding.append(teacher_embedding)\n",
    "        gt_embedding = torch.concatenate(gt_embedding, dim=0)\n",
    "        batch[\"embedding\"] = gt_embedding\n",
    "\n",
    "        # inference\n",
    "        if is_train:\n",
    "            student_model.train()\n",
    "        else:\n",
    "            student_model.eval()\n",
    "        preds = student_model(student_inputs)\n",
    "\n",
    "        # loss\n",
    "        use_cosine = True if epoch < 100 else False\n",
    "        loss, loss_item = detection_loss(preds, batch, use_cosine)\n",
    "        total_loss += loss_item.detach().cpu()\n",
    "        sample_count += batch[\"image\"].shape[0]\n",
    "\n",
    "        # back propagation\n",
    "        if is_train:\n",
    "            scaler.scale(loss).backward()\n",
    "            optimizer_step(student_model, optimizer, scaler)\n",
    "\n",
    "    return total_loss / sample_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = torch.inf\n",
    "for epoch in range(135, epoches):\n",
    "    train_dataset.shuffle()\n",
    "    train_loss = run_one_epoch(epoch, train_loader, student_model, teacher_model, True, optimizer, scaler)\n",
    "    logging.info(f\"epoch: {epoch}\")\n",
    "    logging.info(f\"\\ttrain loss\")\n",
    "    logging.info(f\"\\t\\tdet_loss: {train_loss[0]} cls_loss: {train_loss[1]} dfl_loss: {train_loss[2]} embed_loss: {train_loss[3]}\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    valid_loss = run_one_epoch(epoch, valid_loader, student_model, teacher_model, False)\n",
    "    logging.info(f\"\\tvalid loss\")\n",
    "    logging.info(f\"\\t\\tdet_loss: {valid_loss[0]} cls_loss: {valid_loss[1]} dfl_loss: {valid_loss[2]} embed_loss: {valid_loss[3]}\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    loss = train_loss.sum().detach().cpu().item()\n",
    "    if loss < best_loss:\n",
    "        torch.save(student_model.state_dict(), f\"best_{epoch}.pt\")\n",
    "        best_loss = loss\n",
    "        logging.info(f\"model saved: best_{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset.shuffle()\n",
    "valid_data = next(iter(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 19:35:52.927382: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n"
     ]
    }
   ],
   "source": [
    "images = valid_data[\"image\"]\n",
    "gt_embedding = []\n",
    "for i, img in enumerate(images):\n",
    "    mask = valid_data[\"batch_idx\"] == i\n",
    "    teacher_inputs = []\n",
    "    img_width, img_height, _ = img.shape\n",
    "    xyxy_list = valid_data[\"xyxy\"][mask]\n",
    "    xyxy_list[:, [0, 2]] *= img_width\n",
    "    xyxy_list[:, [1, 3]] *= img_height\n",
    "    xyxy_list = np.round(xyxy_list).astype(np.int32)\n",
    "    for xyxy in xyxy_list:\n",
    "        x1, y1, x2, y2 = xyxy\n",
    "        crop = img[y1:y2, x1:x2, :]\n",
    "        crop = teacher_preprocessor(crop)\n",
    "        teacher_inputs.append(crop)\n",
    "    teacher_inputs = tf.stack(teacher_inputs)\n",
    "    teacher_embedding = teacher_model.pred(teacher_inputs, 8)\n",
    "    gt_embedding.append(teacher_embedding.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_inputs = common.detector_preprocessing(valid_data[\"image\"]).to(device)\n",
    "student_model.eval()\n",
    "pred_det, pred_embed = student_model(student_inputs)\n",
    "result = student_model.postprocess(pred_det, pred_embed, (640, 640), valid_data[\"ori_image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card_info(result):\n",
    "    chromadb = db.ChromaDB()\n",
    "    card_names = []\n",
    "    for np_embed in result.embeds:\n",
    "        embed = np_embed.tolist()\n",
    "        res = chromadb.search_by_embed(embed)\n",
    "        name = res[0][0][\"name\"]\n",
    "        card_names.append(name)\n",
    "    result.names = card_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_card_info(result[0])\n",
    "result[0].save(\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yugioh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
